{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-22T22:17:12.284798Z",
     "start_time": "2024-12-22T22:17:12.279367Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import torch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim import AdamW\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from torch.nn import CrossEntropyLoss"
   ],
   "outputs": [],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T20:19:18.920008Z",
     "start_time": "2024-12-22T20:19:18.905820Z"
    }
   },
   "cell_type": "code",
   "source": "tweets_df = pd.read_csv('data/train.csv')",
   "id": "345baea474e3a6b6",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Data Preprocessing",
   "id": "c6ed9e64160f3e7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T20:19:19.032455Z",
     "start_time": "2024-12-22T20:19:19.025089Z"
    }
   },
   "cell_type": "code",
   "source": "tweets_df.head()",
   "id": "21d344e2677f5e68",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T20:19:19.076826Z",
     "start_time": "2024-12-22T20:19:19.071090Z"
    }
   },
   "cell_type": "code",
   "source": "tweets_df.info()",
   "id": "e5e1b83f84f45055",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7613 entries, 0 to 7612\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   id        7613 non-null   int64 \n",
      " 1   keyword   7552 non-null   object\n",
      " 2   location  5080 non-null   object\n",
      " 3   text      7613 non-null   object\n",
      " 4   target    7613 non-null   int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 297.5+ KB\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T20:19:19.126955Z",
     "start_time": "2024-12-22T20:19:19.123175Z"
    }
   },
   "cell_type": "code",
   "source": "tweets_df['target'].value_counts()",
   "id": "6b90c5962967ca9d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target\n",
       "0    4342\n",
       "1    3271\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T20:19:19.239637Z",
     "start_time": "2024-12-22T20:19:19.236416Z"
    }
   },
   "cell_type": "code",
   "source": "tweets_clean = tweets_df.copy()",
   "id": "2d8d9c29ae07ddbc",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T20:19:19.336514Z",
     "start_time": "2024-12-22T20:19:19.332315Z"
    }
   },
   "cell_type": "code",
   "source": "tweets_clean['keyword'].value_counts()",
   "id": "41ff3c021426351c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "keyword\n",
       "fatalities               45\n",
       "deluge                   42\n",
       "armageddon               42\n",
       "sinking                  41\n",
       "damage                   41\n",
       "                         ..\n",
       "forest%20fire            19\n",
       "epicentre                12\n",
       "threat                   11\n",
       "inundation               10\n",
       "radiation%20emergency     9\n",
       "Name: count, Length: 221, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T20:19:19.385092Z",
     "start_time": "2024-12-22T20:19:19.381350Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Fill missing values and replace regex space\n",
    "tweets_clean['keyword'] = tweets_clean['keyword'].fillna('unknown')\n",
    "tweets_clean['keyword'] = tweets_clean['keyword'].apply(lambda x: x.replace('%20', ' '))"
   ],
   "id": "7a926440190aa03e",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T20:19:19.536392Z",
     "start_time": "2024-12-22T20:19:19.507963Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Combine 'keyword' and 'text' into 'combined_text'\n",
    "def combine_text(row):\n",
    "    keyword = row['keyword']\n",
    "    text = row['text']\n",
    "    return f'keyword: {keyword} text: {text}'\n",
    "\n",
    "tweets_clean['combined_text'] = tweets_clean.apply(combine_text, axis=1)"
   ],
   "id": "54d34e5d01d8fb4b",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T20:19:19.588462Z",
     "start_time": "2024-12-22T20:19:19.562750Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Text cleaning\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    text = re.sub(r'@\\w+', '', text) # remove full mentions\n",
    "    text = re.sub(r'#', '', text) # remove only hashtag sign but leave hashtag text\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "tweets_clean['combined_text'] = tweets_clean['combined_text'].apply(clean_text)"
   ],
   "id": "9d8403a3cef75d60",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T21:01:38.925654Z",
     "start_time": "2024-12-22T21:01:38.903112Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = tweets_clean.drop(columns=['keyword', 'location', 'text'])\n",
    "df.head()"
   ],
   "id": "d2ddc7f818a4c91",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   id  target                                      combined_text\n",
       "0   1       1  keyword unknown text our deeds are the reason ...\n",
       "1   4       1  keyword unknown text forest fire near la ronge...\n",
       "2   5       1  keyword unknown text all residents asked to sh...\n",
       "3   6       1  keyword unknown text 13000 people receive wild...\n",
       "4   7       1  keyword unknown text just got sent this photo ..."
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>combined_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>keyword unknown text our deeds are the reason ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>keyword unknown text forest fire near la ronge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>keyword unknown text all residents asked to sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>keyword unknown text 13000 people receive wild...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>keyword unknown text just got sent this photo ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Define a Dataset Class",
   "id": "585804b54f84fa0c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T21:12:56.636866Z",
     "start_time": "2024-12-22T21:12:56.629095Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class DisasterTweetsDataset(Dataset):\n",
    "    def __init__(self, texts, targets, tokenizer, max_len):\n",
    "        self.texts = texts\n",
    "        self.targets = targets\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        text = self.texts[idx]\n",
    "        target = self.targets[idx]\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            max_length=self.max_len,\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoding['input_ids'].squeeze(),\n",
    "            'attention_mask': encoding['attention_mask'].squeeze(),\n",
    "            'labels': torch.tensor(target, dtype=torch.long),\n",
    "        }"
   ],
   "id": "b47791eb4575d5fb",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Load and Tokenize Data",
   "id": "40df79fe219c1d06"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T21:17:46.297402Z",
     "start_time": "2024-12-22T21:17:44.093678Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "train_texts, test_texts, train_targets, test_targets = train_test_split(\n",
    "    df['combined_text'].tolist(), df['target'].tolist(), test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "train_dataset = DisasterTweetsDataset(train_texts, train_targets, tokenizer, max_len=128)\n",
    "test_dataset = DisasterTweetsDataset(test_texts, test_targets, tokenizer, max_len=128)"
   ],
   "id": "28a14200903585d9",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Define a DataLoader",
   "id": "1ae3a732ed21396b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T21:23:15.147357Z",
     "start_time": "2024-12-22T21:23:15.138561Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=True)"
   ],
   "id": "d0dad5001a4b3960",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Define the Model",
   "id": "68fd91760e93e044"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T22:07:07.981506Z",
     "start_time": "2024-12-22T22:06:14.293576Z"
    }
   },
   "cell_type": "code",
   "source": "model = AutoModelForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)",
   "id": "612a1b324e96c039",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Training",
   "id": "ed953ff5dcae798e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T23:13:22.384130Z",
     "start_time": "2024-12-22T22:17:17.323038Z"
    }
   },
   "cell_type": "code",
   "source": [
    "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "loss_fn = CrossEntropyLoss()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "epochs = 5\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for batch in train_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        loss = outputs.loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch {epoch + 1}/{epochs} completed')"
   ],
   "id": "d54cd58e8044b489",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 completed\n",
      "Epoch 2/5 completed\n",
      "Epoch 3/5 completed\n",
      "Epoch 4/5 completed\n",
      "Epoch 5/5 completed\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Evaluation",
   "id": "5c811574bcc18206"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T23:14:44.434736Z",
     "start_time": "2024-12-22T23:14:10.814447Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch in test_loader:\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, labels=labels)\n",
    "        predictions = torch.argmax(outputs.logits, dim=1)\n",
    "        correct += (predictions == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f'Accuracy: {accuracy}')"
   ],
   "id": "b1e888d0b58bac41",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8266579120157583\n"
     ]
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-22T23:16:03.721492Z",
     "start_time": "2024-12-22T23:16:03.313760Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save the trained model and the tokenizer\n",
    "model_dir = 'model/'\n",
    "\n",
    "model.save_pretrained(model_dir)\n",
    "tokenizer.save_pretrained(model_dir)"
   ],
   "id": "512f1caf47819f8d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('model/tokenizer_config.json',\n",
       " 'model/special_tokens_map.json',\n",
       " 'model/vocab.txt',\n",
       " 'model/added_tokens.json',\n",
       " 'model/tokenizer.json')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "ee36d48a29b8f099"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
